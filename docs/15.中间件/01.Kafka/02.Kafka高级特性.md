---
title: Kafka高级特性解析
date: 2022-03-12 15:06:12
permalink: /pages/15318b/
categories:
  - 中间件
  - kafka
tags:
  - 
---
# Kafka高级特性解析

## 1 生产者

### 1.1 消息发送

#### 1.1.1 数据生产流程解析

![kafka-5](https://gitee.com/linbingxing/image/raw/master/kafka/kafka-5.png)

1. Producer创建时，会创建一个Sender线程并设置为守护线程。

2. 生产消息时，内部其实是异步流程；生产的消息先经过拦截器->序列化器->分区器，然后将消息缓存在缓冲区（该缓冲区也是在Producer创建时创建）。

3. 批次发送的条件为：缓冲区数据大小达到`batch.size`或者`linger.ms`达到上限，哪个先达到就算哪个。

4. 批次发送后，发往指定分区，然后落盘到broker；如果生产者配置了`retrires`参数大于0并且失败原因允许重试，那么客户端内部会对该消息进行重试。

5. 落盘到broker成功，返回生产元数据给生产者。

6. 元数据返回有两种方式：一种是通过阻塞直接返回，另一种是通过回调返回。

#### 1.1.2 参数配置

| **属性**            | **说明**                                                     | **重要性** |
| ------------------- | ------------------------------------------------------------ | ---------- |
| `bootstrap.servers` | 生产者客户端与broker集群建立初始连接需要的broker地址列表，由 该初始连接发现Kafka集群中其他的所有broker。该地址列表不需要写全部的Kafka集群中broker的地址，但也不要写一个，以防该节点 | high       |
| `key.serializer`    | 实现了接口 `org.apache.kafka.common.serialization.Serializer`的key序列化 | high       |
| `value.serializer`  | 实现了接口 `org.apache.kafka.common.serialization.Serializer`的value序列化 | high       |
| `acks`              | 该选项控制着已发送消息的持久性。<br />acks=0：生产者不等待broker的任何消息确认。只要将消息放到了socket的缓冲区，就认为消息已发送。不能保证服务器是否收到该消息，retries设置也不起作用，因为客户端不关心消息是否发送失败。客户端收到的消息偏移量永远是-1。<br />acks=1：leader将记录写到它本地日志，就响应客户端确认消息，而不等待follower副本的确认。如果leader确认了消息就宕机，则可能会丢失消息，因为follower副本可能还没来得及同步该消息。<br />acks=all：leader等待所有同步的副本确认该消息。保证了只要有一个同步副本存在，消息就不会丢失。这是最强的可用性保证。等价于acks=-1。默认值为1，字符串。可选值：[all, -1, 0, 1] | high       |
| `compression.type`  | 生产者生成数据的压缩格式。默认是none（没有压缩）。允许的值：none，gzip，snappy和lz4。压缩是对整个消息批次来讲的。消息批的效率也影响压缩的比例。消息批越大，压缩效率越好。字符串类型的值。默认是none。 | high       |
| `retries`           | 设置该属性为一个大于1的值，将在消息发送失败的时候重新发送消息。该重试与客户端收到异常重新发送并无二至。允许重试但是不设置`max.in.flight.requests.per.connection`为1，存在消息乱序的可能，因为如果两个批次发送到同一个分区，第一个失败了重试，第二个成功了，则第一个消息批在第二个消息批后。int类型的值，默认：0，可选值：[0,...,2147483647] | high       |

#### 1.1.3 序列化器

由于Kafka中的数据都是字节数组，在将消息发送到Kafka之前需要先将数据序列化为字节数组。

序列化器的作用就是用于序列化要发送的消息的。

Kafka使用 `org.apache.kafka.common.serialization.Serializer` 接口用于定义序列化器，将泛型指定类型的数据转换为字节数组。

```java
package org.apache.kafka.common.serialization;

import org.apache.kafka.common.header.Headers;

import java.io.Closeable;
import java.util.Map;

/**
 * An interface for converting objects to bytes. 将对象转换为byte数组的接口
 *
 * A class that implements this interface is expected to have a constructor with no parameter. 该接口的实现类需要提供无参构造器
 * <p>
 * Implement {@link org.apache.kafka.common.ClusterResourceListener} to receive cluster metadata once it's available. Please see the class documentation for ClusterResourceListener for more information.
 *
 * @param <T> Type to be serialized from.
 */
public interface Serializer<T> extends Closeable {

    /**
     * Configure this class. 类的配置信息
     * @param configs configs in key/value pairs
     * @param isKey whether is for key or value key的序列化还是value的序列化
     */
    default void configure(Map<String, ?> configs, boolean isKey) {
        // intentionally left blank
    }

    /**
     * Convert {@code data} into a byte array. 将对象转换为字节数组
     *
     * @param topic topic associated with data 主题名称
     * @param data typed data 需要转换的对象
     * @return serialized bytes 序列化的字节数组
     */
    byte[] serialize(String topic, T data);

    /**
     * Convert {@code data} into a byte array.
     *
     * @param topic topic associated with data
     * @param headers headers associated with the record
     * @param data typed data
     * @return serialized bytes
     */
    default byte[] serialize(String topic, Headers headers, T data) {
        return serialize(topic, data);
    }

    /**
     * Close this serializer. 关闭序列化器 
     * <p>
     * This method must be idempotent as it may be called multiple times. 该方法需要提供幂等性，因为可能调用多次。
     */
    @Override
    default void close() {
        // intentionally left blank
    }
}
```

系统提供了该接口的子接口以及实现类：

| 接口                                                         | 功能 |
| ------------------------------------------------------------ | ---- |
| `org.apache.kafka.common.serialization.StringSerializer`     |      |
| `org.apache.kafka.common.serialization.ByteArraySerializer`  |      |
| `org.apache.kafka.common.serialization.ByteBufferSerializer` |      |
| `org.apache.kafka.common.serialization.IntegerSerializer`    |      |
| `org.apache.kafka.common.serialization.LongDeserializer`     |      |
| `org.apache.kafka.common.serialization.FloatSerializer`      |      |
| `org.apache.kafka.common.serialization.DoubleSerializer`     |      |

自定义序列化器

数据的序列化一般生产中使用`avro`。

自定义序列化器需要实现`org.apache.kafka.common.serialization.Serializer<T>`接口，并实现其中的 serialize 方法。

#### 1.1.4 分区器

默认（`DefaultPartitioner`）分区计算：

1. 如果record提供了分区号，则使用record提供的分区号

2. 如果record没有提供分区号，则使用key的序列化后的值的hash值对分区数量取模

3. 如果record没有提供分区号，也没有提供key，则使用轮询的方式分配分区号。

   - 首先在可用的分区中分配分区号

   - 如果没有可用的分区，则在该主题所有分区中分配分区号。

```java
/**
 * computes partition for given record.
 * if the record has partition returns the value otherwise
 * calls configured partitioner class to compute the partition.
 */
private int partition(ProducerRecord<K, V> record, byte[] serializedKey, byte[] serializedValue, Cluster cluster) {
    Integer partition = record.partition();
    //优化获取配置的分区=号
    return partition != null ?
            partition :
            partitioner.partition(
                    record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);
}


    /**
     * Compute the partition for the given record.
     *
     * @param topic The topic name
     * @param key The key to partition on (or null if no key)
     * @param keyBytes serialized key to partition on (or null if no key)
     * @param value The value to partition on or null
     * @param valueBytes serialized value to partition on or null
     * @param cluster The current cluster metadata
     */
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
        if (keyBytes == null) {
            return stickyPartitionCache.partition(topic, cluster);
        } 
        List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
        int numPartitions = partitions.size();
        // hash the keyBytes to choose a partition
        return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
    }

```

如果要自定义分区器，则需要

1. 首先开发Partitioner接口的实现类

2. 在`KafkaProducer`中进行设置：`configs.put("partitioner.class", "xxx.xx.Xxx.class")`位于 `org.apache.kafka.clients.producer` 中的分区器接口：

```java
package org.apache.kafka.clients.producer;

import org.apache.kafka.common.Configurable;
import org.apache.kafka.common.Cluster;

import java.io.Closeable;

/**
 * Partitioner Interface
 */

public interface Partitioner extends Configurable, Closeable {
     /**
     * Compute the partition for the given record.  为指定的消息记录计算分区值
     * 
     * @param topic The topic name  主题名称
     * @param key The key to partition on (or null if no key) 根据该key的值进行分区计算，如果没有则为null。
     * @param keyBytes The serialized key to partition on( or null if no key) key的序列化字节数组，根据该数组进行分区计算。如果没有key，则为 null
     * @param value The value to partition on or null 根据value值进行分区计算，如果没有，则为null
     * @param valueBytes The serialized value to partition on or null value的序列化字节数组，根据此值进行分区计算。如果没有，则为 null
     * @param cluster The current cluster metadata 当前集群的元数据
     */
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);

    /**
     * This is called when partitioner is closed.
     * 关闭分区器的时候调用该方法 
     */
    public void close();

}
```

#### 1.1.5 过滤器

Producer拦截器（interceptor）和Consumer端Interceptor是在Kafka 0.10版本被引入的，主要用于实现Client端的定制化控制逻辑。

对于Producer而言，Interceptor使得用户在消息发送前以及Producer回调逻辑前有机会对消息做一些定制化需求，比如修改消息等。同时，Producer允许用户指定多个Interceptor按序作用于同一条消息从而形成一个拦截链(interceptor chain)。Intercetpor的实现接口是`org.apache.kafka.clients.producer.ProducerInterceptor`

其定义的方法包括：

- onSend(ProducerRecord)：该方法封装进KafkaProducer.send方法中，即运行在用户主线程中。Producer确保在消息被序列化以计算分区前调用该方法。用户可以在该方法中对消息做任何操作，但最好保证不要修改消息所属的topic和分区，否则会影响目标分区的计算。
- onAcknowledgement(RecordMetadata, Exception)：该方法会在消息被应答之前或消息发送失败时调用，并且通常都是在Producer回调逻辑触发之前。onAcknowledgement运行在Producer的IO线程中，因此不要在该方法中放入很重的逻辑，否则会拖慢Producer的消息发送效率。
- close：关闭Interceptor，主要用于执行一些资源清理工作。

如前所述，Interceptor可能被运行在多个线程中，因此在具体实现时用户需要**自行确保线程安全**。

另外倘若指定了多个Interceptor，则Producer将按照指定顺序调用它们，并仅仅是捕获每个Interceptor可能抛出的异常记录到错误日志中而非在向上传递。这在使用过程中要特别留意。

自定义拦截器：

1. 实现ProducerInterceptor接口

2. 在KafkaProducer的设置中设置自定义的拦截器

   `configs.put("ProducerConfig.INTERCEPTOR_CLASSES_CONFIG", "xxx.xx.interceptor")`

### 1.2 原理解析

![kafka-6](https://gitee.com/linbingxing/image/raw/master/kafka/kafka-6.png)

由上图可以看出：

KafkaProducer有两个基本线程：

- 主线程：负责消息创建，拦截器，序列化器，分区器等操作，并将消息追加到消息收集RecoderAccumulator中；
  - 消息收集器RecoderAccumulator为**每个分区**都维护了一个Deque<ProducerBatch> 类型的双端队列。
  - ProducerBatch 可以理解为是 ProducerRecord 的集合，批量发送有利于提升吞吐量，降低网络影响；
  - 由于生产者客户端使用 java.io.ByteBuffer 在发送消息之前进行消息保存，并维护了一个 BufferPool 实现 ByteBuffer 的复用；该缓存池只针对特定大小（ batch.size指定）的 ByteBuffer进行管理，对于消息过大的缓存，不能做到重复利用。
  - 每次追加一条ProducerRecord消息，会寻找/新建对应的双端队列，从其尾部获取一个ProducerBatch，判断当前消息的大小是否可以写入该批次中。若可以写入则写入；若不可以写入，则新建一个ProducerBatch，判断该消息大小是否超过客户端参数配置 batch.size 的值，不超过，则以 batch.size建立新的ProducerBatch，这样方便进行缓存重复利用；若超过，则以计算的消息大小建立对应的 ProducerBatch ，
  - 缺点就是该内存不能被复用了。

- Sender线程：
  - 该线程从消息收集器获取缓存的消息，将其处理为 <Node, List<ProducerBatch> 的形式， Node 表示集群的broker节点。
  - 进一步将<Node, List<ProducerBatch>转化为<Node, Request>形式，此时才可以向服务端发送数据。
  - 在发送之前，Sender线程将消息以 Map<NodeId, Deque<Request>> 的形式保存到InFlightRequests 中进行缓存，可以通过其获取 leastLoadedNode ,即当前Node中负载压力最小的一个，以实现消息的尽快发出。

## 2 消费者

