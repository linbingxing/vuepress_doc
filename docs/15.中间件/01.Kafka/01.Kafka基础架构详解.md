---
title: Kafka基础架构详解
date: 2022-03-12 13:28:28
permalink: /pages/f9f99f/
categories:
  - 中间件
  - kafka
tags:
  - 
---

#  Kafka基础架构详解

## 1 Kafka介绍

Kafka是最初由Linkedin公司开发，是一个分布式、支持分区的（partition）、多副本的（replica），基于zookeeper协调的分布式消息系统，它的最大的特性就是可以实时的处理大量数据以满足各种需求场景：比如基于hadoop的批处理系统、低延迟的实时系统、Storm/Spark流式处理引擎，web/nginx日志、访问日志，消息服务等等，用scala语言编写，Linkedin于2010年贡献给了Apache基金会并成为顶级开源 项目。

Kafka主要设计目标如下：

- 以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。

- 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。

- 支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。

- 同时支持离线数据处理和实时数据处理。

- 支持在线水平扩展

## 2 Kafka优势

1. 高吞吐量：单机每秒处理几十上百万的消息量。即使存储了许多TB的消息，它也保持稳定的性能。
2. 高性能：单节点支持上千个客户端，并保证零停机和零数据丢失。
3. 持久化数据存储：将消息持久化到磁盘。通过将数据持久化到硬盘以及replication防止数据丢失。
   - 零拷贝
   - 顺序读，顺序写
   - 利用Linux的页缓存
4. 分布式系统，易于向外扩展。所有的Producer、Broker和Consumer都会有多个，均为分布式的。无需停机即可扩展机器。多个Producer、Consumer可能是不同的应用。

5. 可靠性 - Kafka是分布式，分区，复制和容错的。

6. 客户端状态维护：消息被处理的状态是在Consumer端维护，而不是由server端维护。当失败时能自动平衡。

7. 支持online和offline的场景。

8. 支持多种客户端语言。Kafka支持Java、.NET、PHP、Python等多种语言。

## 3 Kafka应用场景

- 日志收集：一个公司可以用Kafka收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、Hbase、Solr等。
- 消息系统：解耦和生产者和消费者、缓存消息等。
- 用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。
- 运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。
- 流式处理：比如Spark Streaming和Storm。

##  4 Kafka基础架构

### 4.1  **消息和批次**

Kafka的数据单元称为消息。可以把消息看成是数据库里的一个“数据行”或一条“记录”。消息由字节数组组成。

消息有键，键也是一个字节数组。当消息以一种可控的方式写入不同的分区时，会用到键。

为了提高效率，消息被分批写入Kafka。批次就是一组消息，这些消息属于同一个主题和分区。

把消息分成批次可以减少网络开销。批次越大，单位时间内处理的消息就越多，单个消息的传输时间就越长。批次数据会被压缩，这样可以提升数据的传输和存储能力，但是需要更多的计算处理。

### 4.2 **主题和分区**

Kafka的消息通过主题进行分类。

主题可比是数据库的表或者文件系统里的文件夹。

主题可以被分为若干分区，一个主题通过分区分布于Kafka集群中，提供了横向扩展的能力。

![kafka-1](https://gitee.com/linbingxing/image/raw/master/kafka/kafka-1.png)

分区是一个**有序的message序列**，这些message按顺序添加到一个叫做**commit log的文件**中。每个分区中的消息都有一个唯一的编号，称之为offset，用来唯一标示某个分区中的message。 

**每个分区，都对应一个commit log文件**。一个分区中的message的offset都是唯一的，但是不同的分区中的message的offset可能是相同的。

kafka一般不会删除消息，不管这些消息有没有被消费。只会根据配置的日志保留时间(log.retention.hours)确认消息多久被删除，默认保留最近一周的日志消息。kafka的性能与保留的消息数据量大小没有关系，因此保存大量的数据消息日志信息不会有什么影响。

**每个consumer是基于自己在commit log中的消费进度(offset)来进行工作的**。在Kafka中，**消费offset由consumer自己来维护**；一般情况下我们按照顺序逐条消费commit log中的消息，当然我可以通过指定offset来重复消费某些消息，或者跳过某些消息。

这意味Kafka中的consumer对集群的影响是非常小的，添加一个或者减少一个consumer，对于集群或者其他consumer来说，都是没有影响的，因为每个consumer维护各自的消费offset。

### 4.3 **生产者和消费者**

生产者创建消息。消费者消费消息。

一个消息被发布到一个特定的主题上。

生产者在默认情况下把消息均衡地分布到主题的所有分区上：

1. 直接指定消息的分区
2. 根据消息的key散列取模得出分区
3.  轮询指定分区。

消费者通过偏移量来区分已经读过的消息，从而消费消息。

消费者是消费组的一部分。消费组保证每个分区只能被一个消费者使用，避免重复消费。

![kafka-2](https://gitee.com/linbingxing/image/raw/master/kafka/kafka-2.png)

### 4.4 broker和集群

一个独立的Kafka服务器称为broker。broker接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。broker为消费者提供服务，对读取分区的请求做出响应，返回已经提交到磁盘上的消息。

**单个broker**可以轻松处理**数千个分区**以及**每秒百万级**的消息量。

每个集群都有一个broker是集群控制器（自动从集群的活跃成员中选举出来）。

- 控制器负责管理工作：

- 将分区分配给broker

监控broker集群中一个分区属于一个**broker**，该broker称为**分区首领**。

**一个分区**可以分配给**多个broker**，此时会发生分区复制。

分区的复制提供了**消息冗余，高可用**。**副本分区**不负责处理消息的读写。

## 5 Kafka核心概念

Kafka是一个分布式的，分区的消息(官方称之为commit log)服务。它提供一个消息系统应该具备的功能，但是确有着独特的设计。可以这样来说，Kafka借鉴了JMS规范的思想，但是确并**没有完全遵循JMS规范。**

首先，让我们来看一下基础的消息(Message)相关术语：

| **名称**      | **解释**                                                     |
| ------------- | ------------------------------------------------------------ |
| Broker        | 消息中间件处理节点，一个Kafka节点就是一个broker，一个或者多个Broker可以组成一个Kafka集群 |
| Topic         | Kafka根据topic对消息进行归类，发布到Kafka集群的每条消息都需要指定一个topic |
| Producer      | 消息生产者，向Broker发送消息的客户端                         |
| Consumer      | 消息消费者，从Broker读取消息的客户端                         |
| ConsumerGroup | 每个Consumer属于一个特定的Consumer Group，一条消息可以被多个不同的Consumer Group消费，但是一个Consumer Group中只能有一个Consumer能够消费该消息 |
| Partition     | 物理上的概念，一个topic可以分为多个partition，每个partition内部消息是有序的 |

因此，从一个较高的层面上来看，producer通过网络发送消息到Kafka集群，然后consumer来进行消费，如下图：![Kafka集群 (1)](https://gitee.com/linbingxing/image/raw/master/kafka/Kafka%E9%9B%86%E7%BE%A4%20(1).jpg)

### **5.1 Producer**

生产者创建消息。

该角色将消息发布到Kafka的topic中。broker接收到生产者发送的消息后，broker将该消息**追加**到当前用于追加数据的 segment 文件中。

一般情况下，一个消息会被发布到一个特定的主题上。

1. 默认情况下通过轮询把消息均衡地分布到主题的所有分区上。

2. 在某些情况下，生产者会把消息直接写到指定的分区。这通常是通过消息键和分区器来实现的，分区器为键生成一个散列值，并将其映射到指定的分区上。这样可以保证包含同一个键的消息会被写到同一个分区上。

3. 生产者也可以使用自定义的分区器，根据不同的业务规则将消息映射到分区。

### **5.2 Consumer**

消费者读取消息。

1. 消费者订阅一个或多个主题，并按照消息生成的顺序读取它们。

2. 消费者通过检查消息的**偏移量**来区分已经读取过的消息。偏移量是另一种元数据，它是一个**不断递增的整数值**，在创建消息时，Kafka 会把它添加到消息里。在给定的**分区**里，每个消息的偏移量都是**唯一**的。消费者把每个分区最后读取的消息偏移量保存在Zookeeper 或**Kafka**上，如果消费者关闭或重启，它的读取状态不会丢失。

3. 消费者是**消费组**的一部分。群组保证每个分区只能被一个消费者使用。

4. 如果一个消费者失效，消费组里的其他消费者可以接管失效消费者的工作，再平衡，分区重新分配。

### **5.3 Broker**

一个独立的Kafka 服务器被称为broker。

broker 为消费者提供服务，对读取分区的请求作出响应，返回已经提交到磁盘上的消息。

1. 如果某topic有N个partition，集群有N个broker，那么每个broker存储该topic的一个partition。 

2. 如果某topic有N个partition，集群有(N+M)个broker，那么其中有N个broker存储该topic的一个partition，剩下的M个broker不存储该topic的partition数据。

3. 如果某topic有N个partition，集群中broker数目少于N个，那么一个broker存储该topic的一个或多个partition。在实际生产环境中，尽量避免这种情况的发生，这种情况容易导致Kafka集群数据不均衡。

broker 是集群的组成部分。每个集群都有一个broker 同时充当了集群控制器的角色（自动从集群的活跃成员中选举出来）。

控制器负责管理工作，包括将分区分配给broker 和监控broker。

在集群中，一个分区从属于一个broker，该broker 被称为分区的首领。

### **5.4 Topic**

每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。

物理上不同Topic的消息分开存储。

主题就好比数据库的表，尤其是分库分表之后的逻辑表。

### **5.5 Partition**

1. 主题可以被分为若干个分区，一个分区就是一个提交日志。

2. 消息以追加的方式写入分区，然后以先入先出的顺序读取。

3. 无法在整个主题范围内保证消息的顺序，但可以保证消息在单个分区内的顺序。

4. Kafka 通过分区来实现数据冗余和伸缩性。

5. 在需要严格保证消息的消费顺序的场景下，需要将partition数目设为1。

### **5.6 Replicas**

Kafka 使用主题来组织数据，每个主题被分为若干个分区，每个分区有多个副本。那些副本被保存

在broker 上，每个broker 可以保存成百上千个属于不同主题和分区的副本。

副本有以下两种类型：

- 首领副本(Leader)

  每个分区都有一个首领副本。为了保证一致性，所有生产者请求和消费者请求都会经过这个副本。

- 跟随者副本(Follower)

  首领以外的副本都是跟随者副本。跟随者副本不处理来自客户端的请求，它们唯一的任务就是从首

  领那里复制消息，保持与首领一致的状态。如果首领发生崩溃，其中的一个跟随者会被提升为新首领。

跟随者副本包括同步副本和不同步副本，在发生首领副本切换的时候，只有同步副本可以切换为首领副本。

**AR**

分区中的所有副本统称为**AR**（Assigned Repllicas）。

 **ISR**

所有与leader副本保持一定程度同步的副本（包括Leader）组成**ISR**（In-Sync Replicas），ISR集合是AR集合中的一个子集。消息会先发送到leader副本，然后follower副本才能从leader副本中拉取消息进行同步，同步期间内follower副本相对于leader副本而言会有一定程度的滞后。前面所说的“一定程度”是指可以忍受的滞后范围，这个范围可以通过参数进行配置。

 **OSR**

与leader副本同步滞后过多的副本（不包括leader）副本，组成**OSR**(Out-Sync Relipcas)。在正常情况下，所有的follower副本都应该与leader副本保持一定程度的同步，即AR=ISR,OSR集合为空。

**HW**

HW是High Watermak的缩写， 俗称高水位，它表示了一个特定消息的偏移量（offset），消费之只能拉取到这个offset之前的消息。

 **LEO**

LEO是Log End Offset的缩写，它表示了当前日志文件中**下一条待写入**消息的offset。

### **5.7 Offset**

**生产者Offset**

消息写入的时候，每一个分区都有一个offset，这个offset就是生产者的offset，同时也是这个分区

的最新最大的offset。

有些时候没有指定某一个分区的offset，这个工作kafka帮我们完成。

**消费者Offset**

这是某一个分区的offset情况，生产者写入的offset是最新最大的值是12，而当Consumer A进行消费时，从0开始消费，一直消费到了6，消费者的offset就记录在6，Consumer B就纪录在了10。等下一次他们再来消费时，他们可以选择接着上一次的位置消费，当然也可以选择从头消费，或者跳到最近的记录并从“现在”开始消费。

![kafka-3](https://gitee.com/linbingxing/image/raw/master/kafka/kafka-3.png)